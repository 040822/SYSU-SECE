{"cells":[{"cell_type":"code","source":["!gdown --id '1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS' --output covid.train.csv\n","!gdown --id '1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg' --output covid.test.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhJ7RYJDhSN7","outputId":"373f922b-b1a6-4a28-fd1f-0ed0c78e3bca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y8NPYt9cW1p"},"outputs":[],"source":["# import packages\n","\n","# Numerical Operations\n","import math\n","import numpy as np\n","\n","# Reading/Writing Data\n","import pandas as pd\n","import os\n","import csv\n","\n","# For Progress Bar\n","from tqdm import tqdm\n","\n","# Pytorch\n","import torch \n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","# For plotting learning curve\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WA9OvHIScb4c"},"outputs":[],"source":["# def three function\n","\n","\n","def same_seed(seed): \n","    '''Fixes random number generator seeds for reproducibility.'''\n","    torch.backends.cudnn.deterministic = True\n","    #A bool that, if True, causes cuDNN to only use deterministic convolution algorithms\n","    torch.backends.cudnn.benchmark = False\n","    #A bool that, if True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest.\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","def train_valid_split(data_set, valid_ratio, seed):\n","    '''Split provided training data into training set and validation set'''\n","    valid_set_size = int(valid_ratio * len(data_set)) \n","    train_set_size = len(data_set) - valid_set_size\n","    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n","    return np.array(train_set), np.array(valid_set)\n","\n","def predict(test_loader, model, device):\n","    model.eval() # Set your model to evaluation mode.\n","    preds = []\n","    for x in tqdm(test_loader):\n","        x = x.to(device)                        \n","        with torch.no_grad():                   \n","            pred = model(x)                     \n","            preds.append(pred.detach().cpu())   \n","    preds = torch.cat(preds, dim=0).numpy()  \n","    return preds\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXR7w9EPcetv"},"outputs":[],"source":["# Dataset\n","\n","class COVID19Dataset(Dataset):\n","    '''\n","    x: Features.\n","    y: Targets, if none, do prediction.\n","    '''\n","    def __init__(self, x, y=None):\n","        if y is None:\n","            self.y = y\n","        else:\n","            self.y = torch.FloatTensor(y)\n","        self.x = torch.FloatTensor(x)\n","\n","    def __getitem__(self, idx):\n","        if self.y is None:\n","            return self.x[idx]\n","        else:\n","            return self.x[idx], self.y[idx]\n","\n","    def __len__(self):\n","        return len(self.x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kqt7rKiciyR"},"outputs":[],"source":["# nnModle\n","\n","class My_Model(nn.Module):\n","    def __init__(self, seq , input_dim):\n","        super(My_Model, self).__init__()\n","        #调用父类的__init__()，且避免钻石继承\n","        \n","        # TODO: modify model's structure, be aware of dimensions. \n","        \n","        #dimensions: input_dim -> 1\n","        \n","        #seq = 0  #change the structure\n","\n","        if seq == 0:\n","\n","          self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 8),\n","            nn.ReLU(),\n","            nn.Linear(8, 1)\n","          )\n","        elif seq == 1:\n","        \n","        # alternative layers\n","          self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 8),\n","            nn.Sigmoid(),\n","            nn.Linear(8, 4),\n","            nn.Hardsigmoid(),\n","            nn.Linear(4,1)\n","          )\n","        elif seq == 2:\n","        \n","        # alternative layers\n","          self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.Sigmoid(),\n","            nn.Linear(16, 8),\n","            nn.Sigmoid(),\n","            nn.Linear(8, 4),\n","            nn.Sigmoid(),\n","            nn.Linear(4,1)\n","          )\n","        elif seq == 3:\n","        # alternative layers\n","          self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.Sigmoid(),\n","            nn.ReLU(),\n","            nn.Linear(16,1)\n","          )\n","        elif seq == 4:\n","        # alternative layers\n","          self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.ReLU(),\n","            nn.Sigmoid(),\n","            nn.Linear(16, 8),\n","            nn.ReLU(),\n","            nn.Sigmoid(),\n","            nn.Hardsigmoid(),\n","            nn.Linear(8, 1)\n","          )\n","\n","        \n","        \n","        \n","\n","        \n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = x.squeeze(1) # (B, 1) -> (B)\n","        #Returns a tensor with all specified dimensions of input of size 1 removed.\n","        return x\n","     "]},{"cell_type":"markdown","metadata":{"id":"jv-BCUnPA8MC"},"source":["# Layers\n","\n","Linear:  y = W * x + b  \n","\n","ReLU: y = max{0,x}  \n","\n","Sigmoid:  y = 1/(1+exp(-x))  \n","\n","Hardsigmoid: $y =\\begin{cases} 0 \\quad if \\ x≤−3, \\\\   1 \\quad if \\ x≥+3\\\\ x/6+1/2  \\quad otherwise \\end{cases}$  \n","\n","and so on  \n","\n"," \n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCL-dQ-LckzH"},"outputs":[],"source":["# Feature Selection\n","\n","def select_feat(train_data, valid_data, test_data, select_all=True):\n","    '''Selects useful features to perform regression'''\n","    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n","    #全部行最后一列 all the rows and the last column\n","    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n","    #全部行除了最后一列 all the rows and all the columns expect the last column\n","    # y is \"Tested Positive Cases\" ,and x are the features\n","    \n","    if select_all:\n","        feat_idx = list(range(raw_x_train.shape[1]))\n","    else:\n","        #feat_idx = [0,1,2,3,4] # TODO: Select suitable feature columns.\n","        feat_idx = [0,1,2,3,4,5,6,7,8,9,10] # TODO: Select suitable feature columns.\n","        \n","    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKL3FNZ-coP0"},"outputs":[],"source":["# Training Loop\n","\n","def trainer(train_loader, valid_loader, model, config, device,op):\n","\n","    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","\n","    # Define your optimization algorithm. \n","    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n","    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n","\n","    #op = 0  change the Algorithm\n","\n","    if op == 0:\n","      optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.9 , weight_decay = 0.01) \n","    elif op == 1:\n","      optimizer = torch.optim.Adagrad(model.parameters(), lr=config['learning_rate'] , weight_decay = 0.01) \n","    elif op == 2:  \n","      optimizer = torch.optim.Rprop(model.parameters(), lr=config['learning_rate'] , etas=(0.5, 1.2), step_sizes=(1e-06, 50))\n","    elif op == 3: \n","      optimizer = torch.optim.RMSprop(model.parameters(), lr=config['learning_rate'], alpha=0.99, eps=1e-08, weight_decay=0.01, momentum=0)\n","    elif op == 4: \n","      optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n","    elif op == 5: \n","      optimizer = torch.optim.RAdam(model.parameters(), lr=config['learning_rate'], betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n","    \"\"\"\n","    L2 regularization: change weight_decay \n","    \n","    class torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, \n","        weight_decay=0, nesterov=False, *, maximize=False, foreach=None, differentiable=False)\n","    \"\"\"\n","    \n","    \n","    \"\"\"\n","    # Algorithms\n","    \n","    SGD 随机梯度下降\n","\n","    Adagrad 自适应梯度算法\n","    \n","    Rprop 弹性反向传播\n","    RMSPROP 均方根反向传播\n","\n","    Adam Adaptive Moment Estimation\n","    RAdam Rectified Adam\n","\n","\n","    and so on\n","    \n","    \n","    \n","    \"\"\"\n","\n","    writer = SummaryWriter() # Writer of tensoboard.\n","\n","    if not os.path.isdir('./models'):\n","        os.mkdir('./models') # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","\n","        # tqdm is a package to visualize your training progress.\n","        # tqdm 进度条库\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","        \n","       \n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)   # Move your data to device. \n","            pred = model(x)             \n","            loss = criterion(pred, y)\n","            loss.backward()                     # Compute gradient(backpropagation).\n","            optimizer.step()                    # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","        writer.add_scalar('Loss/train', mean_train_loss, step)\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_path']) # Save your best model\n","            print('Saving model with loss {:.3f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPk91K5Cc477"},"outputs":[],"source":["# Configurations\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","config = {\n","    'seed': 114514,      # Your seed number, you can pick your lucky number. :)\n","    'select_all': True,   # Whether to use all features.\n","    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n","    'n_epochs': 1000,     # Number of epochs.            \n","    'batch_size': 256, \n","    'learning_rate': 1e-5,              \n","    'early_stop': 400,    # If model has not improved for this many consecutive epochs, stop training.     \n","    'save_path': './models/model.ckpt'  # Your model will be saved here.\n","}\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cLcnWsJpc7lQ"},"outputs":[],"source":["# Dataloader\n","\n","# Set seed for reproducibility\n","same_seed(config['seed'])\n","\n","\n","# train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days) \n","# test_data size: 1078 x 117 (without last day's positive rate)\n","train_data, test_data = pd.read_csv('./covid.train.csv').values, pd.read_csv('./covid.test.csv').values\n","train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n","\n","# Print out the data size.\n","print(f\"\"\"train_data size: {train_data.shape} \n","valid_data size: {valid_data.shape} \n","test_data size: {test_data.shape}\"\"\")\n","\n","# Select features\n","x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n","\n","# Print out the number of features.\n","print(f'number of features: {x_train.shape[1]}')\n","\n","train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n","                                            COVID19Dataset(x_valid, y_valid), \\\n","                                            COVID19Dataset(x_test)\n","\n","# Pytorch data loader loads pytorch dataset into batches.\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yt2fkt3Rc94f"},"outputs":[],"source":["# Start training!\n","\n","for op in [0,2,3]:\n","  for seq in range(1):\n","    model = My_Model(seq,input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n","\n","    trainer(train_loader, valid_loader, model, config, device,op)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB4kBb7odhBW"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zcNOVTtdzr9"},"outputs":[],"source":["def save_pred(preds, file):\n","    ''' Save predictions to specified file '''\n","    with open(file, 'w') as fp:\n","        writer = csv.writer(fp)\n","        writer.writerow(['id', 'tested_positive'])\n","        for i, p in enumerate(preds):\n","            writer.writerow([i, p])\n","#for seq in range(4):\n","model = My_Model(0,input_dim=x_train.shape[1]).to(device)\n","model.load_state_dict(torch.load(config['save_path']))\n","preds = predict(test_loader, model, device) \n","save_pred(preds, 'pred.csv')         "]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}